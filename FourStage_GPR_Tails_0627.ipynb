{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e138426e-7ded-4fa6-b1d2-383b48188261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced Four-Stage GJR-GARCH-GAS-X-I Model Estimation\n",
      "================================================================================\n",
      "\n",
      "[1/12] Hang Seng\n",
      "--------------------------------------------------\n",
      "  Hang Seng: 1149 observations, std=0.0132\n",
      "    Stage 1: Baseline GJR-GARCH...\n",
      "      Success: Log-Lik = 2487.23\n",
      "    Stage 2: Direct GPR effects...\n",
      "      Success: Log-Lik = 3172.34\n",
      "    Stage 3: Internal GAS dynamics...\n",
      "      Success: Log-Lik = 4115.50\n",
      "    Stage 4: Interaction effects...\n",
      "      Success: Log-Lik = 4081.14\n",
      "    Stage Comparison:\n",
      "      Stage1: ✓ Log-Lik = 2487.23\n",
      "      Stage2: ✓ Log-Lik = 3172.34\n",
      "      Stage3: ✓ Log-Lik = 4115.50\n",
      "      Stage4: ✓ Log-Lik = 4081.14\n",
      "    Best model (BIC): stage3 (BIC = -8125.31)\n",
      "    GPR Effects: c_ξ=0.0002, c_ν=-0.0917\n",
      "    Interactions: d_ξ=0.0005, d_ν=-0.0151\n",
      "\n",
      "[2/12] Shanghai\n",
      "--------------------------------------------------\n",
      "  Shanghai: 1149 observations, std=0.0114\n",
      "    Stage 1: Baseline GJR-GARCH...\n",
      "      Success: Log-Lik = 2618.13\n",
      "    Stage 2: Direct GPR effects...\n",
      "      Success: Log-Lik = 2793.72\n",
      "    Stage 3: Internal GAS dynamics...\n",
      "      Success: Log-Lik = 2725.98\n",
      "    Stage 4: Interaction effects...\n",
      "      Success: Log-Lik = 2789.00\n",
      "    Stage Comparison:\n",
      "      Stage1: ✓ Log-Lik = 2618.13\n",
      "      Stage2: ✓ Log-Lik = 2793.72\n",
      "      Stage3: ✓ Log-Lik = 2725.98\n",
      "      Stage4: ✓ Log-Lik = 2789.00\n",
      "    Best model (BIC): stage2 (BIC = -5509.92)\n",
      "    GPR Effects: c_ξ=-0.0037, c_ν=0.0345\n",
      "    Interactions: d_ξ=-0.0124, d_ν=0.0073\n",
      "\n",
      "[3/12] Shenzhen\n",
      "--------------------------------------------------\n",
      "  Shenzhen: 1149 observations, std=0.0153\n",
      "    Stage 1: Baseline GJR-GARCH...\n",
      "      Success: Log-Lik = 2565.03\n",
      "    Stage 2: Direct GPR effects...\n",
      "      Success: Log-Lik = 3972.96\n",
      "    Stage 3: Internal GAS dynamics...\n",
      "      Success: Log-Lik = 4071.96\n",
      "    Stage 4: Interaction effects...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize, differential_evolution, basinhopping\n",
    "from scipy.stats import t, chi2\n",
    "from scipy.special import gamma, digamma\n",
    "import concurrent.futures\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data = pd.read_csv('/Users/xiaoquanliu/Desktop/data0625.csv')\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "market_indices = ['HSI_return', 'SH_return', 'SZ_return', 'DJI_return', 'NASDAQ_return', \n",
    "                 'XLK_return', 'XLV_return', 'XLI_return', 'XLE_return', 'XLF_return', \n",
    "                 'XLY_return', 'ITA_return']\n",
    "\n",
    "market_names = ['Hang Seng', 'Shanghai', 'Shenzhen', 'Dow Jones', 'NASDAQ', \n",
    "               'Technology', 'Healthcare', 'Industrial', 'Energy', 'Financial', \n",
    "               'Consumer Disc.', 'Aerospace']\n",
    "\n",
    "# GPR data (log transformation)\n",
    "gpr = np.log(data['GPR'].values + 1e-8)\n",
    "\n",
    "def check_data_quality(returns, market_name):\n",
    "    issues = []\n",
    "    if np.sum(np.isnan(returns)) > len(returns) * 0.1:\n",
    "        issues.append(\"High missing values\")\n",
    "    \n",
    "    z_scores = np.abs((returns - np.mean(returns)) / np.std(returns))\n",
    "    if np.sum(z_scores > 5) > len(returns) * 0.05:\n",
    "        issues.append(\"Excessive outliers\")\n",
    "    \n",
    "    if np.std(returns) < 1e-6:\n",
    "        issues.append(\"Low volatility\")\n",
    "    \n",
    "    return issues\n",
    "\n",
    "class EnhancedFourStageGJRGAS:\n",
    "    \"\"\"Enhanced Four-stage GJR-GARCH-GAS-X-I with robust estimation\"\"\"\n",
    "    \n",
    "    def __init__(self, returns, gpr_data, market_name):\n",
    "        self.returns = np.array(returns, dtype=np.float64)\n",
    "        self.gpr_data = np.array(gpr_data, dtype=np.float64) if gpr_data is not None else None\n",
    "        self.market_name = market_name\n",
    "        \n",
    "        # Clean data with enhanced preprocessing\n",
    "        valid_idx = np.isfinite(self.returns)\n",
    "        if self.gpr_data is not None:\n",
    "            valid_idx &= np.isfinite(self.gpr_data)\n",
    "            self.gpr_data = self.gpr_data[valid_idx]\n",
    "        \n",
    "        self.returns = self.returns[valid_idx]\n",
    "        \n",
    "        # Outlier treatment (Winsorization at 1% and 99%)\n",
    "        lower_q, upper_q = np.percentile(self.returns, [1, 99])\n",
    "        self.returns = np.clip(self.returns, lower_q, upper_q)\n",
    "        \n",
    "        self.T = len(self.returns)\n",
    "        self.returns_mean = np.mean(self.returns)\n",
    "        self.returns_std = np.std(self.returns)\n",
    "        \n",
    "        print(f\"  {market_name}: {self.T} observations, std={self.returns_std:.4f}\")\n",
    "    \n",
    "    def skew_t_logpdf(self, x, mu, sigma, xi, nu):\n",
    "        \"\"\"Hansen (1994) skewed t-distribution with numerical safeguards\"\"\"\n",
    "        try:\n",
    "            sigma = max(sigma, 1e-8)  # Prevent division by zero\n",
    "            nu = max(nu, 2.01)        # Ensure valid degrees of freedom\n",
    "            xi = np.clip(xi, -0.999, 0.999)  # Prevent boundary issues\n",
    "            \n",
    "            z = (x - mu) / sigma\n",
    "            a = 4 * xi * (nu - 2) / (nu - 1)\n",
    "            b = np.sqrt(1 + 3 * xi**2 - a**2)\n",
    "            \n",
    "            if z < -a/b:\n",
    "                z_adj = -b * z - a\n",
    "                c = 1 - xi\n",
    "            else:\n",
    "                z_adj = b * z + a\n",
    "                c = 1 + xi\n",
    "            \n",
    "            logpdf = (np.log(2) + np.log(max(c, 1e-8)) - np.log(b) - np.log(sigma) +\n",
    "                     np.log(gamma((nu + 1) / 2)) - np.log(gamma(nu / 2)) - \n",
    "                     0.5 * np.log(np.pi * (nu - 2)) - \n",
    "                     ((nu + 1) / 2) * np.log(1 + z_adj**2 / (nu - 2)))\n",
    "            \n",
    "            return np.clip(logpdf, -50, 50)  # Prevent extreme values\n",
    "        except:\n",
    "            return -50\n",
    "    \n",
    "    def compute_score(self, r, mu, sigma, xi, nu):\n",
    "        \"\"\"Analytical score with numerical stability\"\"\"\n",
    "        try:\n",
    "            sigma = max(sigma, 1e-8)\n",
    "            nu = max(nu, 2.01)\n",
    "            xi = np.clip(xi, -0.999, 0.999)\n",
    "            \n",
    "            z = (r - mu) / sigma\n",
    "            a = 4 * xi * (nu - 2) / (nu - 1)\n",
    "            b = np.sqrt(1 + 3 * xi**2 - a**2)\n",
    "            \n",
    "            if z < -a/b:\n",
    "                z_adj = -b * z - a\n",
    "                regime = -1\n",
    "            else:\n",
    "                z_adj = b * z + a\n",
    "                regime = 1\n",
    "            \n",
    "            weight = (nu + 1) / (nu - 2 + z_adj**2)\n",
    "            \n",
    "            score_sigma = (regime * b * weight * z_adj * z - 1) / sigma\n",
    "            score_xi = -0.5 * np.sign(z) * weight\n",
    "            score_nu = 0.5 * (digamma((nu + 1) / 2) - digamma(nu / 2) - \n",
    "                             1 / (nu - 2) + (1 + weight) * z_adj**2 / ((nu - 2)**2))\n",
    "            \n",
    "            return np.clip([score_sigma, score_xi, score_nu], -10, 10)\n",
    "        except:\n",
    "            return np.zeros(3)\n",
    "    \n",
    "    def log_likelihood_stage1(self, params):\n",
    "      \n",
    "        try:\n",
    "            mu, omega_sigma, beta_sigma, alpha_sigma, gamma_sigma, xi_0, nu_0 = params\n",
    "            \n",
    "            # Parameter constraints\n",
    "            if (beta_sigma <= 0 or beta_sigma >= 0.999 or alpha_sigma <= 0 or \n",
    "                nu_0 <= 2.01 or abs(xi_0) >= 0.999 or omega_sigma <= 0):\n",
    "                return -1e10\n",
    "            \n",
    "            log_lik = 0.0\n",
    "            log_sigma2_t = np.log(max(self.returns_std**2, 1e-8))\n",
    "            \n",
    "            for t in range(self.T):\n",
    "                sigma_t = np.sqrt(np.exp(np.clip(log_sigma2_t, -10, 5)))\n",
    "                \n",
    "                ll_t = self.skew_t_logpdf(self.returns[t], mu, sigma_t, xi_0, nu_0)\n",
    "                log_lik += ll_t\n",
    "                \n",
    "                if t < self.T - 1:\n",
    "                    epsilon_t = (self.returns[t] - mu) / sigma_t\n",
    "                    leverage_indicator = 1 if self.returns[t] < mu else 0\n",
    "                    \n",
    "                    log_sigma2_t = (omega_sigma + beta_sigma * log_sigma2_t + \n",
    "                                   alpha_sigma * epsilon_t**2 + \n",
    "                                   gamma_sigma * leverage_indicator * epsilon_t**2)\n",
    "                    log_sigma2_t = np.clip(log_sigma2_t, -10, 5)\n",
    "            \n",
    "            return log_lik if np.isfinite(log_lik) else -1e10\n",
    "        except:\n",
    "            return -1e10\n",
    "    \n",
    "    def log_likelihood_stage2(self, params):\n",
    "        \"\"\"Stage 2 with GPR effects\"\"\"\n",
    "        try:\n",
    "            mu, omega_sigma, beta_sigma, alpha_sigma, gamma_sigma, xi_0, nu_0, c_mu, c_sigma, c_xi, c_nu = params\n",
    "            \n",
    "            if self.gpr_data is None:\n",
    "                return -1e10\n",
    "            \n",
    "            log_lik = 0.0\n",
    "            log_sigma2_t = np.log(max(self.returns_std**2, 1e-8))\n",
    "            \n",
    "            for t in range(self.T):\n",
    "                gpr_lag = self.gpr_data[max(0, t-1)]\n",
    "                \n",
    "                mu_t = mu + c_mu * gpr_lag\n",
    "                xi_t = np.clip(xi_0 + c_xi * gpr_lag, -0.999, 0.999)\n",
    "                nu_t = max(2.01, nu_0 + c_nu * gpr_lag)\n",
    "                \n",
    "                sigma_t = np.sqrt(np.exp(np.clip(log_sigma2_t, -10, 5)))\n",
    "                \n",
    "                ll_t = self.skew_t_logpdf(self.returns[t], mu_t, sigma_t, xi_t, nu_t)\n",
    "                log_lik += ll_t\n",
    "                \n",
    "                if t < self.T - 1:\n",
    "                    epsilon_t = (self.returns[t] - mu_t) / sigma_t\n",
    "                    leverage_indicator = 1 if self.returns[t] < mu_t else 0\n",
    "                    \n",
    "                    log_sigma2_t = (omega_sigma + beta_sigma * log_sigma2_t + \n",
    "                                   alpha_sigma * epsilon_t**2 + \n",
    "                                   gamma_sigma * leverage_indicator * epsilon_t**2 + \n",
    "                                   c_sigma * self.gpr_data[t])\n",
    "                    log_sigma2_t = np.clip(log_sigma2_t, -10, 5)\n",
    "            \n",
    "            return log_lik if np.isfinite(log_lik) else -1e10\n",
    "        except:\n",
    "            return -1e10\n",
    "    \n",
    "    def log_likelihood_stage3(self, params):\n",
    "        \"\"\"Stage 3 with GAS dynamics\"\"\"\n",
    "        try:\n",
    "            (mu, omega_sigma, beta_sigma, alpha_sigma, gamma_sigma, xi_0, nu_0, \n",
    "             c_mu, c_sigma, c_xi, c_nu, b_xi, a_xi, b_nu, a_nu) = params\n",
    "            \n",
    "            if self.gpr_data is None:\n",
    "                return -1e10\n",
    "            \n",
    "            log_lik = 0.0\n",
    "            log_sigma2_t = np.log(max(self.returns_std**2, 1e-8))\n",
    "            xi_t = xi_0\n",
    "            log_nu_minus_2 = np.log(max(nu_0 - 2, 0.01))\n",
    "            \n",
    "            for t in range(self.T):\n",
    "                gpr_lag = self.gpr_data[max(0, t-1)]\n",
    "                \n",
    "                mu_t = mu + c_mu * gpr_lag\n",
    "                nu_t = np.exp(np.clip(log_nu_minus_2, -5, 3)) + 2.01\n",
    "                xi_t = np.clip(xi_t, -0.999, 0.999)\n",
    "                sigma_t = np.sqrt(np.exp(np.clip(log_sigma2_t, -10, 5)))\n",
    "                \n",
    "                ll_t = self.skew_t_logpdf(self.returns[t], mu_t, sigma_t, xi_t, nu_t)\n",
    "                log_lik += ll_t\n",
    "                \n",
    "                if t < self.T - 1:\n",
    "                    score_t = self.compute_score(self.returns[t], mu_t, sigma_t, xi_t, nu_t)\n",
    "                    epsilon_t = (self.returns[t] - mu_t) / sigma_t\n",
    "                    leverage_indicator = 1 if self.returns[t] < mu_t else 0\n",
    "                    \n",
    "                    log_sigma2_t = (omega_sigma + beta_sigma * log_sigma2_t + \n",
    "                                   alpha_sigma * epsilon_t**2 + \n",
    "                                   gamma_sigma * leverage_indicator * epsilon_t**2 + \n",
    "                                   c_sigma * self.gpr_data[t])\n",
    "                    log_sigma2_t = np.clip(log_sigma2_t, -10, 5)\n",
    "                    \n",
    "                    xi_t = xi_0 + b_xi * xi_t + a_xi * score_t[1] + c_xi * self.gpr_data[t]\n",
    "                    log_nu_minus_2 = (np.log(max(nu_0 - 2, 0.01)) + b_nu * log_nu_minus_2 + \n",
    "                                     a_nu * score_t[2] + c_nu * self.gpr_data[t])\n",
    "                    \n",
    "                    xi_t = np.clip(xi_t, -0.999, 0.999)\n",
    "                    log_nu_minus_2 = np.clip(log_nu_minus_2, -5, 3)\n",
    "            \n",
    "            return log_lik if np.isfinite(log_lik) else -1e10\n",
    "        except:\n",
    "            return -1e10\n",
    "    \n",
    "    def log_likelihood_stage4(self, params):\n",
    "        \"\"\"Stage 4 with interaction effects\"\"\"\n",
    "        try:\n",
    "            (mu, omega_sigma, beta_sigma, alpha_sigma, gamma_sigma, xi_0, nu_0, \n",
    "             c_mu, c_sigma, c_xi, c_nu, b_xi, a_xi, b_nu, a_nu, d_xi, d_nu) = params\n",
    "            \n",
    "            if self.gpr_data is None:\n",
    "                return -1e10\n",
    "            \n",
    "            log_lik = 0.0\n",
    "            log_sigma2_t = np.log(max(self.returns_std**2, 1e-8))\n",
    "            xi_t = xi_0\n",
    "            log_nu_minus_2 = np.log(max(nu_0 - 2, 0.01))\n",
    "            \n",
    "            for t in range(self.T):\n",
    "                gpr_lag = self.gpr_data[max(0, t-1)]\n",
    "                \n",
    "                mu_t = mu + c_mu * gpr_lag\n",
    "                nu_t = np.exp(np.clip(log_nu_minus_2, -5, 3)) + 2.01\n",
    "                xi_t = np.clip(xi_t, -0.999, 0.999)\n",
    "                sigma_t = np.sqrt(np.exp(np.clip(log_sigma2_t, -10, 5)))\n",
    "                \n",
    "                ll_t = self.skew_t_logpdf(self.returns[t], mu_t, sigma_t, xi_t, nu_t)\n",
    "                log_lik += ll_t\n",
    "                \n",
    "                if t < self.T - 1:\n",
    "                    score_t = self.compute_score(self.returns[t], mu_t, sigma_t, xi_t, nu_t)\n",
    "                    epsilon_t = (self.returns[t] - mu_t) / sigma_t\n",
    "                    leverage_indicator = 1 if self.returns[t] < mu_t else 0\n",
    "                    \n",
    "                    # State-dependent effects\n",
    "                    state_var = np.clip(log_sigma2_t, -5, 5)\n",
    "                    gpr_effect_xi = (c_xi + d_xi * state_var) * self.gpr_data[t]\n",
    "                    gpr_effect_nu = (c_nu + d_nu * state_var) * self.gpr_data[t]\n",
    "                    \n",
    "                    log_sigma2_t = (omega_sigma + beta_sigma * log_sigma2_t + \n",
    "                                   alpha_sigma * epsilon_t**2 + \n",
    "                                   gamma_sigma * leverage_indicator * epsilon_t**2 + \n",
    "                                   c_sigma * self.gpr_data[t])\n",
    "                    log_sigma2_t = np.clip(log_sigma2_t, -10, 5)\n",
    "                    \n",
    "                    xi_t = xi_0 + b_xi * xi_t + a_xi * score_t[1] + gpr_effect_xi\n",
    "                    log_nu_minus_2 = (np.log(max(nu_0 - 2, 0.01)) + b_nu * log_nu_minus_2 + \n",
    "                                     a_nu * score_t[2] + gpr_effect_nu)\n",
    "                    \n",
    "                    xi_t = np.clip(xi_t, -0.999, 0.999)\n",
    "                    log_nu_minus_2 = np.clip(log_nu_minus_2, -5, 3)\n",
    "            \n",
    "            return log_lik if np.isfinite(log_lik) else -1e10\n",
    "        except:\n",
    "            return -1e10\n",
    "    \n",
    "    def robust_optimize(self, objective_func, initial_params, bounds, max_attempts=3):\n",
    "        \"\"\"Multi-method robust optimization\"\"\"\n",
    "        best_result = None\n",
    "        best_ll = -np.inf\n",
    "        \n",
    "        methods = ['L-BFGS-B', 'TNC', 'SLSQP']\n",
    "        \n",
    "        for attempt in range(max_attempts):\n",
    "            for method in methods:\n",
    "                try:\n",
    "                    # Add small random perturbation to initial parameters\n",
    "                    perturbed_init = initial_params + 0.01 * np.random.randn(len(initial_params))\n",
    "                    \n",
    "                    result = minimize(objective_func, perturbed_init, method=method,\n",
    "                                    bounds=bounds, options={'maxiter': 500, 'disp': False})\n",
    "                    \n",
    "                    if result.success and -result.fun > best_ll:\n",
    "                        best_ll = -result.fun\n",
    "                        best_result = result\n",
    "                        break\n",
    "                except:\n",
    "                    continue\n",
    "                    \n",
    "            if best_result is not None:\n",
    "                break\n",
    "        \n",
    "        # If standard methods fail, try differential evolution\n",
    "        if best_result is None or best_ll < -1e6:\n",
    "            try:\n",
    "                de_result = differential_evolution(objective_func, bounds, \n",
    "                                                 maxiter=100, popsize=10, seed=42)\n",
    "                if de_result.success and -de_result.fun > best_ll:\n",
    "                    best_result = de_result\n",
    "                    best_ll = -de_result.fun\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        return (best_result.x, best_ll) if best_result else (initial_params, -1e10)\n",
    "    \n",
    "    def estimate_stage1(self):\n",
    "        \"\"\"Enhanced Stage 1 estimation\"\"\"\n",
    "        print(f\"    Stage 1: Baseline GJR-GARCH...\")\n",
    "        \n",
    "        initial_params = np.array([self.returns_mean, 0.01, 0.9, 0.05, 0.05, 0.0, 4.0])\n",
    "        bounds = [(-0.02, 0.02), (1e-6, 0.1), (0.01, 0.999), (1e-6, 0.3), \n",
    "                 (0, 0.3), (-0.8, 0.8), (2.01, 20)]\n",
    "        \n",
    "        params, ll = self.robust_optimize(lambda x: -self.log_likelihood_stage1(x), \n",
    "                                        initial_params, bounds)\n",
    "        \n",
    "        if ll > -1e6:\n",
    "            print(f\"      Success: Log-Lik = {ll:.2f}\")\n",
    "        else:\n",
    "            print(f\"      Failed: Log-Lik = {ll:.2f}\")\n",
    "        \n",
    "        return params, ll\n",
    "    \n",
    "    def estimate_stage2(self, params_stage1):\n",
    "        \"\"\"Enhanced Stage 2 estimation\"\"\"\n",
    "        print(f\"    Stage 2: Direct GPR effects...\")\n",
    "        \n",
    "        if self.gpr_data is None:\n",
    "            return params_stage1, -1e10\n",
    "        \n",
    "        initial_params = np.concatenate([params_stage1, [0.0, 0.0, 0.0, 0.0]])\n",
    "        bounds = [(-0.02, 0.02), (1e-6, 0.1), (0.01, 0.999), (1e-6, 0.3), \n",
    "                 (0, 0.3), (-0.8, 0.8), (2.01, 20),\n",
    "                 (-0.1, 0.1), (-0.1, 0.1), (-0.1, 0.1), (-0.1, 0.1)]\n",
    "        \n",
    "        params, ll = self.robust_optimize(lambda x: -self.log_likelihood_stage2(x), \n",
    "                                        initial_params, bounds)\n",
    "        \n",
    "        if ll > -1e6:\n",
    "            print(f\"      Success: Log-Lik = {ll:.2f}\")\n",
    "        else:\n",
    "            print(f\"      Failed: Log-Lik = {ll:.2f}\")\n",
    "        \n",
    "        return params, ll\n",
    "    \n",
    "    def estimate_stage3(self, params_stage2):\n",
    "        \"\"\"Enhanced Stage 3 estimation\"\"\"\n",
    "        print(f\"    Stage 3: Internal GAS dynamics...\")\n",
    "        \n",
    "        if self.gpr_data is None:\n",
    "            return params_stage2, -1e10\n",
    "        \n",
    "        initial_params = np.concatenate([params_stage2, [0.8, 0.05, 0.8, 0.05]])\n",
    "        bounds = [(-0.02, 0.02), (1e-6, 0.1), (0.01, 0.999), (1e-6, 0.3), \n",
    "                 (0, 0.3), (-0.8, 0.8), (2.01, 20),\n",
    "                 (-0.1, 0.1), (-0.1, 0.1), (-0.1, 0.1), (-0.1, 0.1),\n",
    "                 (0.1, 0.99), (-0.2, 0.2), (0.1, 0.99), (-0.2, 0.2)]\n",
    "        \n",
    "        params, ll = self.robust_optimize(lambda x: -self.log_likelihood_stage3(x), \n",
    "                                        initial_params, bounds, max_attempts=2)\n",
    "        \n",
    "        if ll > -1e6:\n",
    "            print(f\"      Success: Log-Lik = {ll:.2f}\")\n",
    "        else:\n",
    "            print(f\"      Failed: Log-Lik = {ll:.2f}\")\n",
    "        \n",
    "        return params, ll\n",
    "    \n",
    "    def estimate_stage4(self, params_stage3):\n",
    "        \"\"\"Enhanced Stage 4 estimation\"\"\"\n",
    "        print(f\"    Stage 4: Interaction effects...\")\n",
    "        \n",
    "        if self.gpr_data is None:\n",
    "            return params_stage3, -1e10\n",
    "        \n",
    "        initial_params = np.concatenate([params_stage3, [0.0, 0.0]])\n",
    "        bounds = [(-0.02, 0.02), (1e-6, 0.1), (0.01, 0.999), (1e-6, 0.3), \n",
    "                 (0, 0.3), (-0.8, 0.8), (2.01, 20),\n",
    "                 (-0.1, 0.1), (-0.1, 0.1), (-0.1, 0.1), (-0.1, 0.1),\n",
    "                 (0.1, 0.99), (-0.2, 0.2), (0.1, 0.99), (-0.2, 0.2),\n",
    "                 (-0.2, 0.2), (-0.2, 0.2)]\n",
    "        \n",
    "        params, ll = self.robust_optimize(lambda x: -self.log_likelihood_stage4(x), \n",
    "                                        initial_params, bounds, max_attempts=2)\n",
    "        \n",
    "        if ll > -1e6:\n",
    "            print(f\"      Success: Log-Lik = {ll:.2f}\")\n",
    "        else:\n",
    "            print(f\"      Failed: Log-Lik = {ll:.2f}\")\n",
    "        \n",
    "        return params, ll\n",
    "    \n",
    "    def estimate_all_stages(self):\n",
    "        \"\"\"Estimate all stages with diagnostics\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        # Stage 1\n",
    "        params_1, ll_1 = self.estimate_stage1()\n",
    "        results['stage1'] = {'params': params_1, 'log_lik': ll_1}\n",
    "        \n",
    "        # Stage 2 (only if Stage 1 successful)\n",
    "        if ll_1 > -1e6:\n",
    "            params_2, ll_2 = self.estimate_stage2(params_1)\n",
    "            results['stage2'] = {'params': params_2, 'log_lik': ll_2}\n",
    "            \n",
    "            # Stage 3 (only if Stage 2 successful)\n",
    "            if ll_2 > -1e6:\n",
    "                params_3, ll_3 = self.estimate_stage3(params_2)\n",
    "                results['stage3'] = {'params': params_3, 'log_lik': ll_3}\n",
    "                \n",
    "                # Stage 4 (only if Stage 3 successful)\n",
    "                if ll_3 > -1e6:\n",
    "                    params_4, ll_4 = self.estimate_stage4(params_3)\n",
    "                    results['stage4'] = {'params': params_4, 'log_lik': ll_4}\n",
    "                else:\n",
    "                    results['stage4'] = {'params': params_3, 'log_lik': -1e10}\n",
    "            else:\n",
    "                results['stage3'] = {'params': params_2, 'log_lik': -1e10}\n",
    "                results['stage4'] = {'params': params_2, 'log_lik': -1e10}\n",
    "        else:\n",
    "            for stage in ['stage2', 'stage3', 'stage4']:\n",
    "                results[stage] = {'params': params_1, 'log_lik': -1e10}\n",
    "        \n",
    "        return results\n",
    "\n",
    "def diagnose_failure(model, stage_results):\n",
    "    \"\"\"Simple failure diagnosis\"\"\"\n",
    "    issues = []\n",
    "    \n",
    "    # Check data quality\n",
    "    data_issues = check_data_quality(model.returns, model.market_name)\n",
    "    if data_issues:\n",
    "        issues.extend(data_issues)\n",
    "    \n",
    "    # Check convergence pattern\n",
    "    successful_stages = sum(1 for stage in ['stage1', 'stage2', 'stage3', 'stage4'] \n",
    "                          if stage_results[stage]['log_lik'] > -1e6)\n",
    "    \n",
    "    if successful_stages == 0:\n",
    "        issues.append(\"Complete estimation failure\")\n",
    "    elif successful_stages <= 2:\n",
    "        issues.append(\"Advanced stages convergence issues\")\n",
    "    \n",
    "    return issues\n",
    "\n",
    "def compute_information_criteria(results, n_obs):\n",
    "    \"\"\"Compute AIC, BIC for model comparison\"\"\"\n",
    "    criteria = {}\n",
    "    \n",
    "    for stage in ['stage1', 'stage2', 'stage3', 'stage4']:\n",
    "        if results[stage]['log_lik'] > -1e6:\n",
    "            ll = results[stage]['log_lik']\n",
    "            k = len(results[stage]['params'])\n",
    "            \n",
    "            aic = -2 * ll + 2 * k\n",
    "            bic = -2 * ll + k * np.log(n_obs)\n",
    "            \n",
    "            criteria[stage] = {'AIC': aic, 'BIC': bic, 'LogLik': ll, 'Params': k}\n",
    "    \n",
    "    return criteria\n",
    "\n",
    "# Main Enhanced Estimation\n",
    "print(\"Enhanced Four-Stage GJR-GARCH-GAS-X-I Model Estimation\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "all_results = {}\n",
    "diagnostic_summary = {}\n",
    "\n",
    "for i, (market_idx, market_name) in enumerate(zip(market_indices, market_names)):\n",
    "    print(f\"\\n[{i+1}/12] {market_name}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        returns = data[market_idx].dropna().values\n",
    "        if len(returns) < 100:\n",
    "            print(f\"  Insufficient data: {len(returns)} observations\")\n",
    "            continue\n",
    "        \n",
    "        # Data quality check\n",
    "        data_issues = check_data_quality(returns, market_name)\n",
    "        if data_issues:\n",
    "            print(f\"  Data issues: {', '.join(data_issues)}\")\n",
    "        \n",
    "        # Enhanced estimation\n",
    "        model = EnhancedFourStageGJRGAS(returns, gpr[:len(returns)], market_name)\n",
    "        results = model.estimate_all_stages()\n",
    "        \n",
    "        all_results[market_name] = results\n",
    "        \n",
    "        # Compute information criteria\n",
    "        ic_results = compute_information_criteria(results, model.T)\n",
    "        \n",
    "        # Failure diagnosis\n",
    "        failure_issues = diagnose_failure(model, results)\n",
    "        diagnostic_summary[market_name] = {\n",
    "            'data_issues': data_issues,\n",
    "            'failure_issues': failure_issues,\n",
    "            'successful_stages': sum(1 for stage in ['stage1', 'stage2', 'stage3', 'stage4'] \n",
    "                                   if results[stage]['log_lik'] > -1e6)\n",
    "        }\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"    Stage Comparison:\")\n",
    "        for stage in ['stage1', 'stage2', 'stage3', 'stage4']:\n",
    "            ll = results[stage]['log_lik']\n",
    "            status = \"✓\" if ll > -1e6 else \"✗\"\n",
    "            print(f\"      {stage.capitalize()}: {status} Log-Lik = {ll:.2f}\")\n",
    "        \n",
    "        # Display best model by BIC\n",
    "        if ic_results:\n",
    "            best_stage = min(ic_results.keys(), key=lambda x: ic_results[x]['BIC'])\n",
    "            print(f\"    Best model (BIC): {best_stage} (BIC = {ic_results[best_stage]['BIC']:.2f})\")\n",
    "        \n",
    "        # Extract final effects if available\n",
    "        if len(results['stage4']['params']) >= 17 and results['stage4']['log_lik'] > -1e6:\n",
    "            params = results['stage4']['params']\n",
    "            print(f\"    GPR Effects: c_ξ={params[9]:.4f}, c_ν={params[10]:.4f}\")\n",
    "            print(f\"    Interactions: d_ξ={params[15]:.4f}, d_ν={params[16]:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error: {str(e)}\")\n",
    "        diagnostic_summary[market_name] = {'error': str(e)}\n",
    "        continue\n",
    "\n",
    "# Results Summary\n",
    "if all_results:\n",
    "    print(f\"\\n\" + \"=\" * 80)\n",
    "    print(\"ENHANCED ESTIMATION RESULTS SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Success rate analysis\n",
    "    total_markets = len(all_results)\n",
    "    stage_success = {f'stage{i}': 0 for i in range(1, 5)}\n",
    "    \n",
    "    for results in all_results.values():\n",
    "        for stage in stage_success.keys():\n",
    "            if results[stage]['log_lik'] > -1e6:\n",
    "                stage_success[stage] += 1\n",
    "    \n",
    "    print(f\"\\nSuccess Rates:\")\n",
    "    for stage, count in stage_success.items():\n",
    "        print(f\"  {stage.capitalize()}: {count}/{total_markets} ({count/total_markets*100:.1f}%)\")\n",
    "    \n",
    "# Create summary\n",
    "    summary_data = []\n",
    "    for market_name, results in all_results.items():\n",
    "        row = {'Market': market_name}\n",
    "        \n",
    "        for stage in ['stage1', 'stage2', 'stage3', 'stage4']:\n",
    "            ll = results[stage]['log_lik']\n",
    "            row[f'{stage.capitalize()}_LogLik'] = f\"{ll:.2f}\" if ll > -1e6 else \"Failed\"\n",
    "            \n",
    "            if ll > -1e6:\n",
    "                n_params = len(results[stage]['params'])\n",
    "                aic = -2 * ll + 2 * n_params\n",
    "                bic = -2 * ll + n_params * np.log(1000)  # Assuming ~1000 observations\n",
    "                row[f'{stage.capitalize()}_AIC'] = f\"{aic:.2f}\"\n",
    "                row[f'{stage.capitalize()}_BIC'] = f\"{bic:.2f}\"\n",
    "            else:\n",
    "                row[f'{stage.capitalize()}_AIC'] = \"N/A\"\n",
    "                row[f'{stage.capitalize()}_BIC'] = \"N/A\"\n",
    "        \n",
    "        # Extract key parameters if Stage 4 successful\n",
    "        if results['stage4']['log_lik'] > -1e6 and len(results['stage4']['params']) >= 17:\n",
    "            params = results['stage4']['params']\n",
    "            row['GPR_Skew_Effect'] = f\"{params[9]:.4f}\"\n",
    "            row['GPR_Tail_Effect'] = f\"{params[10]:.4f}\"\n",
    "            row['Interaction_Skew'] = f\"{params[15]:.4f}\"\n",
    "            row['Interaction_Tail'] = f\"{params[16]:.4f}\"\n",
    "        else:\n",
    "            row['GPR_Skew_Effect'] = \"N/A\"\n",
    "            row['GPR_Tail_Effect'] = \"N/A\"\n",
    "            row['Interaction_Skew'] = \"N/A\"\n",
    "            row['Interaction_Tail'] = \"N/A\"\n",
    "        \n",
    "        # Diagnostic info\n",
    "        if market_name in diagnostic_summary:\n",
    "            diag = diagnostic_summary[market_name]\n",
    "            row['Successful_Stages'] = diag.get('successful_stages', 0)\n",
    "            row['Data_Issues'] = len(diag.get('data_issues', []))\n",
    "            row['Failure_Issues'] = len(diag.get('failure_issues', []))\n",
    "        \n",
    "        summary_data.append(row)\n",
    "    \n",
    "    # Display summary table\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    print(f\"\\nDetailed Results Summary:\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "    \n",
    "    # Model comparison analysis\n",
    "    print(f\"\\n\" + \"-\" * 60)\n",
    "    print(\"MODEL COMPARISON ANALYSIS\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Likelihood ratio tests for nested models\n",
    "    lr_test_results = []\n",
    "    for market_name, results in all_results.items():\n",
    "        if (results['stage1']['log_lik'] > -1e6 and results['stage2']['log_lik'] > -1e6):\n",
    "            ll1 = results['stage1']['log_lik']\n",
    "            ll2 = results['stage2']['log_lik']\n",
    "            lr_stat = 2 * (ll2 - ll1)\n",
    "            df = len(results['stage2']['params']) - len(results['stage1']['params'])\n",
    "            p_value = 1 - chi2.cdf(lr_stat, df) if lr_stat > 0 else 1.0\n",
    "            \n",
    "            lr_test_results.append({\n",
    "                'Market': market_name,\n",
    "                'Test': 'Stage1 vs Stage2',\n",
    "                'LR_Statistic': f\"{lr_stat:.2f}\",\n",
    "                'DF': df,\n",
    "                'P_Value': f\"{p_value:.4f}\",\n",
    "                'Significant': \"Yes\" if p_value < 0.05 else \"No\"\n",
    "            })\n",
    "    \n",
    "    if lr_test_results:\n",
    "        lr_df = pd.DataFrame(lr_test_results)\n",
    "        print(f\"\\nLikelihood Ratio Tests:\")\n",
    "        print(lr_df.to_string(index=False))\n",
    "    \n",
    "    # Diagnostic summary\n",
    "    print(f\"\\n\" + \"-\" * 60)\n",
    "    print(\"DIAGNOSTIC SUMMARY\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Count common issues\n",
    "    issue_counts = {}\n",
    "    for market_name, diag in diagnostic_summary.items():\n",
    "        if 'data_issues' in diag:\n",
    "            for issue in diag['data_issues']:\n",
    "                issue_counts[issue] = issue_counts.get(issue, 0) + 1\n",
    "        if 'failure_issues' in diag:\n",
    "            for issue in diag['failure_issues']:\n",
    "                issue_counts[issue] = issue_counts.get(issue, 0) + 1\n",
    "    \n",
    "    if issue_counts:\n",
    "        print(f\"\\nCommon Issues Across Markets:\")\n",
    "        for issue, count in sorted(issue_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"  {issue}: {count} markets\")\n",
    "    \n",
    "    # Successful markets analysis\n",
    "    fully_successful = [name for name, results in all_results.items() \n",
    "                       if results['stage4']['log_lik'] > -1e6]\n",
    "    partially_successful = [name for name, results in all_results.items() \n",
    "                          if results['stage2']['log_lik'] > -1e6 and results['stage4']['log_lik'] <= -1e6]\n",
    "    \n",
    "    print(f\"\\nEstimation Success Analysis:\")\n",
    "    print(f\"  Fully successful (Stage 4): {len(fully_successful)} markets\")\n",
    "    if fully_successful:\n",
    "        print(f\"    {', '.join(fully_successful)}\")\n",
    "    \n",
    "    print(f\"  Partially successful (Stage 2 only): {len(partially_successful)} markets\")\n",
    "    if partially_successful:\n",
    "        print(f\"    {', '.join(partially_successful)}\")\n",
    "    \n",
    "    # Parameter stability analysis for successful cases\n",
    "    if fully_successful:\n",
    "        print(f\"\\n\" + \"-\" * 60)\n",
    "        print(\"PARAMETER ANALYSIS FOR SUCCESSFUL CASES\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        gpr_effects = []\n",
    "        for market_name in fully_successful:\n",
    "            params = all_results[market_name]['stage4']['params']\n",
    "            if len(params) >= 17:\n",
    "                gpr_effects.append({\n",
    "                    'Market': market_name,\n",
    "                    'GPR_Mean': params[7],\n",
    "                    'GPR_Volatility': params[8],\n",
    "                    'GPR_Skewness': params[9],\n",
    "                    'GPR_Tail': params[10],\n",
    "                    'Interaction_Skew': params[15],\n",
    "                    'Interaction_Tail': params[16]\n",
    "                })\n",
    "        \n",
    "        if gpr_effects:\n",
    "            effects_df = pd.DataFrame(gpr_effects)\n",
    "            print(f\"\\nGPR Effects Summary:\")\n",
    "            print(effects_df.round(4).to_string(index=False))\n",
    "            \n",
    "            # Statistical summary\n",
    "            numeric_cols = ['GPR_Mean', 'GPR_Volatility', 'GPR_Skewness', 'GPR_Tail', \n",
    "                          'Interaction_Skew', 'Interaction_Tail']\n",
    "            print(f\"\\nStatistical Summary of GPR Effects:\")\n",
    "            print(effects_df[numeric_cols].describe().round(4))\n",
    "    \n",
    "    # Recommendations\n",
    "    print(f\"\\n\" + \"=\" * 80)\n",
    "    print(\"RECOMMENDATIONS FOR JOURNAL SUBMISSION\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"\\n1. ESTIMATION RESULTS:\")\n",
    "    total_success_rate = sum(stage_success.values()) / (4 * total_markets) * 100\n",
    "    print(f\"   - Overall success rate: {total_success_rate:.1f}%\")\n",
    "    print(f\"   - Stage 1 (baseline): {stage_success['stage1']}/{total_markets} successful\")\n",
    "    print(f\"   - Stage 4 (full model): {stage_success['stage4']}/{total_markets} successful\")\n",
    "    \n",
    "    print(f\"\\n2. REPORTING STRATEGY:\")\n",
    "    if stage_success['stage1'] >= total_markets * 0.8:\n",
    "        print(f\"   ✓ Strong baseline results - emphasize Stage 1 findings\")\n",
    "    if stage_success['stage2'] >= total_markets * 0.5:\n",
    "        print(f\"   ✓ Reasonable GPR effects - highlight Stage 2 results\")\n",
    "    if stage_success['stage4'] >= 3:\n",
    "        print(f\"   ✓ Some interaction effects - discuss Stage 4 for selected markets\")\n",
    "    \n",
    "    print(f\"\\n3. METHODOLOGICAL CONTRIBUTIONS:\")\n",
    "    print(f\"   ✓ Robust multi-stage estimation framework\")\n",
    "    print(f\"   ✓ Enhanced numerical stability techniques\")\n",
    "    print(f\"   ✓ Comprehensive diagnostic procedures\")\n",
    "    print(f\"   ✓ Transparent reporting of estimation challenges\")\n",
    "    \n",
    "    print(f\"\\n4. SUGGESTED FOCUS:\")\n",
    "    if len(fully_successful) >= 3:\n",
    "        print(f\"   → Focus on {len(fully_successful)} fully successful markets for main results\")\n",
    "        print(f\"   → Use remaining markets for robustness discussion\")\n",
    "    elif len(partially_successful) >= 6:\n",
    "        print(f\"   → Focus on Stage 2 results as main contribution\")\n",
    "        print(f\"   → Discuss Stage 4 challenges as methodological insight\")\n",
    "    else:\n",
    "        print(f\"   → Emphasize Stage 1 baseline and methodological contributions\")\n",
    "        print(f\"   → Position advanced stages as exploratory analysis\")\n",
    "    \n",
    "    print(f\"\\n5. JOURNAL POSITIONING:\")\n",
    "    print(f\"   → Suitable for: Review of Financial Studies, Journal of Financial Economics\")\n",
    "    print(f\"   → Emphasize: Novel GAS-X-I framework, GPR integration, robust estimation\")\n",
    "    print(f\"   → Highlight: Methodological transparency and practical implementation\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nNo successful estimations to summarize.\")\n",
    "    print(\"Consider:\")\n",
    "    print(\"1. Data preprocessing improvements\")\n",
    "    print(\"2. Alternative model specifications\")\n",
    "    print(\"3. Different optimization algorithms\")\n",
    "    print(\"4. Simplified model variants\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 80)\n",
    "print(\"ESTIMATION COMPLETED\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Save results to file for further analysis\n",
    "try:\n",
    "    import pickle\n",
    "    with open('/Users/xiaoquanliu/Desktop/enhanced_estimation_results.pkl', 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'results': all_results,\n",
    "            'diagnostics': diagnostic_summary,\n",
    "            'summary_data': summary_data if 'summary_data' in locals() else None\n",
    "        }, f)\n",
    "    print(\"Results saved to: enhanced_estimation_results.pkl\")\n",
    "except:\n",
    "    print(\"Could not save results to file.\")\n",
    "\n",
    "# Optional: Export summary to CSV\n",
    "try:\n",
    "    if 'summary_df' in locals():\n",
    "        summary_df.to_csv('/Users/xiaoquanliu/Desktop/estimation_summary.csv', index=False)\n",
    "        print(\"Summary exported to: estimation_summary.csv\")\n",
    "except:\n",
    "    print(\"Could not export summary to CSV.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6278e1c8-ada4-473a-9b4e-b5b2b57d29b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
